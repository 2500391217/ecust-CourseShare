1. 第一章：

    1. 计算机设计目标是什么？

        > 性能 性价比 性能功耗比
        >
        > “在设计时，在价格、可获得性、功耗等条件约束下，最大化性能。”
        >
    2. 我们可以如何分类计算机？

        > 弗林分类法
        >
        > SISD：单**指令**（instruction）流单**数据流**（data）
        >
        > SIMD：向量机 多媒体扩展处理 GPU
        >
        > MISD：紧耦合MIMD: SMP、DSM 松散耦合MIMD: 机群cluster
        >
        > MIMD：无商用产品 数据流处理机
        >
    3. 【计算】晶体管动态功耗

        > 1.晶体管动态功耗的含义是什么，由哪些因素决定？
        >
        > 电流热效应导致的芯片耗能。容性负载，电压^2^和开关频率。
        >
        > 2.现代一些微处理器设计采用可调电压，电压下降15%可能导致频率下降15%，这对动态能耗和动态功率有什么影响？
        >
        > 由于电容不变，能耗变化就是电压平方之比：
        >
        > `能耗_新/能耗_原=(电压×0.85)^2/电压^2=0.85^2 =0.72`
        >
        > 能耗下降为72%。对于功率，需要考虑频率变化：
        >
        > `新功率/原功率=0.72×开关频率×0.85/开关频率=0.61`
        >
    4. 【计算】关于系统可靠性的计算

        > 设磁盘子系统组件和MTTF如下，求系统的MTTF。
        >
        > > 10个磁盘，每个MTTF=1 000 000小时
        > > 1个ATA控制器，MTTF=500 000小时
        > > 1个电源，MTTF=200 000小时
        > > 1个风扇， MTTF=200 000小时
        > > 1根ATA电缆，MTTF= 1000 000小时
        >
        >
        > 假设各个故障源互相独立，整个系统故障率是各个组件故障率之和。
        >
        > > 系统故障率=10×1/1 000 000+1/500 000+1/200 000+1/200 000+1/100 0000 = 10+2+5+5+1/1 000 000=23/1 000 000=23000/1000 000 000小时
        >
        > > 系统MTTF=1/系统故障率=1 000 000 000/23 000 =43500小时
        >
        >
        > 系统增加一个备用电源，系统的MTTF变为多少？
        >
        > > 假设系统组件发生故障相互独立。新系统(双电源系统，或者电源对系统)其中一个电源发生故障时，由于第二个电源的保障，系统依然能够正常工作。当一个电源发生故障，没有来得及修理，第二电源也发生故障，这时系统发生故障。
        >
        > > p1×p2=2/MMTF×MTTR/MTTF => MTTF^2/2∗MTTR
        >
        > 
    5. 计算机设计遵循基本原则

        > 局部性（两个）原理、利用并行性（四种）、聚焦一般情况
        >
    6. 【计算】关于等效CPI

        > 假设有以下情况，用处理器性能公式对比两种方案。
        >
        > > FP运算频率=25%， FP运算的CPI=4，其他指令的CPI=1.33
        > > FPSQR运算(浮点平方根)频率=2%，FPSQR的CPI=20
        > > 有两种设计方案，一种方案将FPSQR的CPI降至2。另外一 种将
        > > 所有FP运算CPI降至2.5
        >
        >
        > > 仅有CPI发生改变，指令条数和时钟周期不变。没改进前的原CPI：
        >
        > > 原CPI=∑CPI_i×(IC_i/指令数)=(4×25%)+(1.33×75%)=2
        >
        > > 可以用原CPI减去节省的周期数得到改进FPSQR后的CPI
        >
        > > CPI_改进FPSQR后=CPI_原−2%×(CPI_旧FPSQR−CPI_新FPSQR)
        > > =2.0-2%×(20-2)=1.64
        >
        > > 对所有的FP改进后的CPI为：
        >
        > > CPI_新FP=(75%×1.33)+(25%×2.5)=1.625
        >
        > > 对所有FP改进后的CPI低一些，这种方案的效果好一些。该种方案的加速比为
        >
        > > 加速比_新FP=CPU时间_原/CPU时间_新FP=IC×时钟周期×CPI_原/IC×时钟周期×CPI_新FP=CPI_原/CPI_新FP=2/1.625=1.23
        >
        > 
    7. 【计算】关于Amdahl定律

        > 假设我们希望升级一个提供Web服务的处理器。新处理器的计算速度是旧处理器的10倍。假定原处理器有40%的时间用于计算，60%的时间等待I/O操作。进行升级后，总加速比是多少？
        >
        > > 升级比例 0.4 ，升级加速比 10，所以总的加速比
        >
        > > 1/0.6+0.4/10=1/0.64≈1.56
        >
        >
        > 图形处理器经常需要求平方根，比较以下两种设计方案。
        >
        > > 第一种将浮点平方根(FPSQR)硬件加速到原来的10倍，FPSQR占据了原来总执行时间的20%，另外一种设计方案，将所有的FP浮点运算速度提高到原来的1.6倍，浮点运算占据原执行时间比利为50%。
        >
        >
        > > 通过计算加速比来比较两种设计方案
        > > 加速比_FPSQR=1/(1−0.2)+0.2/10=1/0.82=1.22
        > > 加速比_FP=1/(1−0.5)+0.5/1.6=1/0.8125=1.23
        >
        > > 提高整体FP浮点运算速度的方案稍好一些，因为它的使用频率要高一些
        >
        > 
2. 第二章：

    1. RISC主流指令集

        > ARM、RISC-V、MIPS LoongArch
        >
        > 包括算术指令，控制指令和存取指令
        >
        > 算术指令不访存，存取指令不译码，控制指令只有取址译码
        >
    2. 流水线性能指标

        > 吞吐率：单位时间内流水线完成的任务数量。<br />加速比：完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间比
        > 流水线效率：流水线中的设备实际使用时间与整个运行时间的比值，即流水线设备的利用率。
        >
        > 理想状况下，流水线的CPI=1，流水线的加速比等于流水线级数(pipeline depth)
        > 实际上 加速比=流水线级数/(1-分支指令频率*条件指令导致的空闲/停顿周期数)
        >
    3. 分支延迟转移

        > 在条件指令后面插入一条不相关的指令。 实现：分支延迟槽
        >
    4. 分支预测

        > 预测分支指令/条件指令的方向——转移成功或转移不成功
        >
        > 动态分支预测：根据程序行为动态预测转移方向，转移方向动态变化
        >
        > 静态分支预测：预测方向固定，根据编译阶段的信息来预测方向，根据早期运行情况来预测转移方向
        >
        > 2-bit：猜，对了接着猜，错两次就改。
        >
    5. 多周期5段RISC流水线分析

        > 取指令(Instruction fetch, IF)：根据程序计数器 PC 取到当前指令<br />指令译码(Instruction decode, ID)：译码指令，读取寄存器操作数<br />检测条件指令的条件码，判定是否要跳转 计算条件指令的跳转目标地址<br />执行指令(Execution, EX ) 形成有效地址(存储器操作数)：基地址+偏移量 执行寄存器-寄存器型或者寄存器-立即数型 ALU 指令<br />访问存储器 Memory access (MEM)对于 Load 指令，利用前面 EX 阶段得到的有效地址，从存储器读入操作数对于 Store 指令，将数据写到存储器<br />写回 (Write back, WB)对于寄存器-寄存器 ALU 指令或者 Load 指令，把结果写到寄存器堆
        >
        > 计算指令不访存 存储指令不译码 控制指令只有取指和译码
        >
3. 第三章：

    1. 名称相关

        > 名称相关：两条指令使用相同的寄存器名称和相同的内存地址，却没有信息流动交换。不是真实的数据相关
        >
        > 反相关：读后写、输出相关：写后写
        >
    2. 结构冒险、控制相关

        > 结构冒险：流水线中某条指令可能会需要被其他条指令占用的资源，这会导致结构冒险(structural hazard)
        >
        > 控制相关：就是某条指令与条件指令相关，是否会被执行取决于分支指令
        >
    3. 数据冒险

        > 只要指令之间存在名称相关或者数据相关，而且指令排得比较近，指令间的重叠执行会改变对操作数的访问顺序，就会存在风险。
        >
        > WAW  WAR  RAW
        >
    4. 相关预测：gshare预测器

        > 分支语句的地址 xor 分支的前十次历史 =》 1024*2-bit
        >
    5. 竞赛预测器

        > 全局 局部 选择器
        >
    6. Tomasulo 算法指令动态调度分析 略
    7. 带ROB的Tomasulo动态调度分析 略
    8. 寄存器重命名

        > WAW WAR 通过保留栈(reservation station)实现
        >
        > 当操作数可获得时，保留栈去取操作数，并缓存到保留栈中
        >
        > 给等待执行指令指派提供操作数的保留栈
        >
        > 指令执行结果可以通过公共数据总线CDB(common data bus)广播传递
        >
        > 如果若干条重叠执行指令的目的寄存器相同，只有最后的输出值会更新寄存器堆
        >
        > 当指令被发射，用保留栈编号名称来重新命名寄存器
        >
    9. 处理器微结构：

        > 顺序发射、顺序提交、乱序执行
        >
    10. 循环展开局限性

         > 1、随循环展开次数增加，平均每个迭代步的循环开销(计算循环变量、分支语句)减少量，变得越来越少
         >
         > 2、循环展开会让增加代码的长度，增加指令的条数
         >
         > 3、寄存器压力：循环展开会增加寄存器的需求数量
         >
    11. 多发射过程

         > 给将要发射的下一个指令束中每条指令，分配保留栈和重排序缓冲区空间。
         >
         > 分配保留栈时，限定能在一个指令束里一起发射的每类指令的指令条数，比如一条FP运算、一条Load、一条Store、一条整型指令
         >
         > 检查指令束中指令间的相关性，如果指令束内指令间之间存在相关性，用指令对应的重排序缓冲区编码来更新保留栈表，记录相关性
         > 同时也需要支持多条指令完成、多条指令提交
         >
4. 第四章：

    1. 存储器层次结构->存储墙

        > 略
        >
    2. Cache高级优化方法：

        > 提高Cache带宽：分组结构、无阻塞、流水线结构
        >
        > 减少命中时间 增加Cache带宽  减少不命中时间开销 减少不命中率 利用并行性减少不命中时间开销和不命中率
        >
    3. Cache映射

        > 直接相联 组相联 全相联
        >
    4. Cache替换方法

        > FIFO LRU 随机
        >
    5. Cache更新方法比较

        > 写回法、写直达法
        >
5. 第五章：

    1. 挖掘数据级并行性三种结构

        > GPU  向量机 SIMD多媒体扩展
        >
    2. SIMD多媒体扩展

        > SSE MMX AVX
        >
    3. GPU的调度器

        > 线程调度器、线程块调度器
        >
    4. SIMD多媒体扩展与向量机不同

        > 很容易实现，只需要对标准ALU增加些许开销
        >
        > 只需要少许额外状态 易于上下文转换context switch
        >
        > 只需要增加少许的额外带宽
        >
        > 没有虚拟存储器的页面错误、跨页访问等问题
        >
        > 易于引入新的指令，支持新的多媒体数据标准
        >
    5. 屋脊线Roofline性能模型

        > 画出峰值浮点运算吞吐量随算术密度变化的曲线
        > 将浮点性能、存储器性能、算术强度关系反映到2D图形中
        > 这是一种比较各种SIMD体系结构性能的直观可视化方法
        >
    6. 向量机：集中-分散操作

        > 集中操作：使用索引向量，取到稀疏矩阵中非零元素
        > .   ---LVI (load vector indexed or gather)
        > 分散操作：当以紧凑形式完成操作处理之后，稀疏向量可以采用相同的索引向量，扩展回原来的分散形式
        >  ---SVI (store vector indexed or scatter)
        >
6. 第六章：

    1. 消息传递系统、共享存储器系统

        > 并行结构，分为消息传递系统(MPP、Cluster)和共享存储系统(SMP、DSM)
        > 消息传递系统：每个处理器有自己的私有存储器，处理器间通过显式消息通信
        > 共享存储系统：多个处理器共享一个存储器，通信通过共享存储器实现
        > 多核处理器与共享内存多处理器相似，一个核运行一个线程
        >
    2. LLC

        > UCA结构：集中式共享LLC，Cache访问延迟一样，扩展性弱，适合核数较少的情况
        > NUCA结构：分布式共享LLC，访问延迟不一样，需要高效查询替换算法，扩展性强，适合核数较多和众核(>64核)的情况
        >
    3. Cache一致性

        > Cache一致性：在共享存储器系统中，维持数据在存储器和多个处理器或多个核的私有Cache中的数据副本一致
        >
    4. 监听协议和目录协议、适用场景、优劣

        > 监听协议：当某个处理器写一个共享数据时，将写无效信号通过信道广播给所有的处理器。每个处理器监听信道，看无效信号是否与自己的Cache副本有关，如果是则将副本作废。
        > 场景：常用于SMP系统，需要广播，适合于共享总线结构。
        > 优劣：总线是独占共享资源，延迟会随处理器数量增多而增加，限制了连接的处理器数量
        > 目录协议：为每个存储行维持一目录项, 记录所有当前持有此行数据备份的处理器号以及是否已被改写等信息。
        > 场景：多用于DSM系统，当一个处理器核写数引起数据不一致时, 它就根据目录的内容只向持该数据备份的处理器发出写无效/信号, 避免了广播。
        > 优劣：扩展性比较好，可以连接较多数量的处理器。
        >
    5. 互连网络

        > 多核处理器通过互连网络将处理器核、Cache、内存控制器、IO 接口等模块连接起来。
        >
    6. 硬件多线程

        1. 粗粒度多线程

            > 每个时钟周期切换一次进程。多线程指令交替执行
            > 如果某个进程出现停顿，更换另外一个进程
            > 可以隐藏流水线执行中长短停顿，但是会推迟单个进程执行
            >
        2. 细粒度多线程

            > 只有遇到长停顿，比如最后一级Cache不命中，才切换进程
            > 减少进程切换频率，加快单个进程执行，简化硬件
            > 不能隐藏短停顿，比如数据相关
            > 流水线清空装入开销大
            >
        3. SMT同时多线程

            > 在多发射、动态调度处理器中，挖掘指令并行性的基础上，挖掘线程并行性
            > 在多发射、动态调度处理器中，受指令间相关性的限制，单个线程不能充分利用处理器功能部件并行性
            > 从多个线程调度指令，一次多发射包含来自不同线程的指令，当功能部件可以用，执行来自不同线程的指令。从而，让多线程指令并行执行
            > 线程内数据相关性由寄存器重名来解决